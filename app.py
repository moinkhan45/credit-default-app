# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bHUyMHBYZr18mNMihd0rsNeAJZMR0JrL
"""

import streamlit as st
import pandas as pd
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    accuracy_score, roc_auc_score,
    precision_score, recall_score,
    f1_score, matthews_corrcoef,
    confusion_matrix, classification_report
)

st.set_page_config(page_title="Credit Default Classification", layout="wide")

st.title("ðŸ’³ Credit Card Default Prediction")
st.write("Upload test CSV file and evaluate different ML models.")

# Upload CSV
uploaded_file = st.file_uploader("Upload Test Dataset (CSV)", type=["csv"])

# Model Selection
model_option = st.selectbox(
    "Select Model",
    [
        "Logistic Regression",
        "Decision Tree",
        "KNN",
        "Naive Bayes",
        "Random Forest",
        "XGBoost"
    ]
)

# Model file mapping
model_files = {
    "Logistic Regression": "models/logistic_model.pkl",
    "Decision Tree": "models/decision_tree.pkl",
    "KNN": "models/knn.pkl",
    "Naive Bayes": "models/naive_bayes.pkl",
    "Random Forest": "models/random_forest.pkl",
    "XGBoost": "models/xgboost.pkl"
}

if uploaded_file is not None:

    data = pd.read_csv(uploaded_file)

    # Remove ID column if present
    if "ID" in data.columns:
        data = data.drop("ID", axis=1)

    target_column = "default.payment.next.month"

    if target_column not in data.columns:
        st.error("Target column not found in uploaded file!")
    else:

        X = data.drop(target_column, axis=1)
        y = data[target_column]

        model = joblib.load(model_files[model_option])

        # Prediction
        y_pred = model.predict(X)
        y_prob = model.predict_proba(X)[:, 1]

        # Metrics
        accuracy = accuracy_score(y, y_pred)
        auc = roc_auc_score(y, y_prob)
        precision = precision_score(y, y_pred, zero_division=0)
        recall = recall_score(y, y_pred, zero_division=0)
        f1 = f1_score(y, y_pred, zero_division=0)
        mcc = matthews_corrcoef(y, y_pred)

        st.subheader("ðŸ“Š Evaluation Metrics")
        col1, col2, col3 = st.columns(3)

        col1.metric("Accuracy", round(accuracy, 4))
        col1.metric("AUC", round(auc, 4))

        col2.metric("Precision", round(precision, 4))
        col2.metric("Recall", round(recall, 4))

        col3.metric("F1 Score", round(f1, 4))
        col3.metric("MCC", round(mcc, 4))

        # Confusion Matrix
        st.subheader("ðŸ”¢ Confusion Matrix")
        cm = confusion_matrix(y, y_pred)

        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", ax=ax)
        ax.set_xlabel("Predicted")
        ax.set_ylabel("Actual")
        st.pyplot(fig)

        # Classification Report
        st.subheader("ðŸ“„ Classification Report")
        st.text(classification_report(y, y_pred))